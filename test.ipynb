{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf358348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download from the ğŸ¤— Hub\n",
    "model = SentenceTransformer(\"CocoRoF/POLAR-Qwen3-0.6b-linq-gist\", tokenizer_kwargs={\"padding_side\": \"left\"},)\n",
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda913d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\", tokenizer_kwargs={\"padding_side\": \"left\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07490515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8819, 0.7349]])\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    'ì„¸ê³„ëŠ” ë‚¨ìê°€ ì¤‘ì‹¬ì´ê³  ì´ ì„¸ìƒì„ ì§€ë°°í•˜ëŠ” ìë“¤ì´ë‹¤'\n",
    "]\n",
    "\n",
    "documents = [\n",
    "    \"ì„¸ê³„ëŠ” ì—¬ìê°€ ì¤‘ì‹¬ì´ê³  ì´ ì„¸ìƒì„ ì§€ë°°í•˜ëŠ” ìë“¤ì´ë‹¤\",\n",
    "    \"ë‚˜ëŠ” ì•„ë¹ ê°€ ì¢‹ë‹¤. ì—­ì‹œ ê°€ë¶€ì¥ì  ì‚¬ê³ ê°€ í•„ìš”í•´ ì—„ë§ˆ ë¯¸ì›Œ\"\n",
    "]\n",
    "\n",
    "query_embeddings = model.encode(queries, prompt_name=\"query\")\n",
    "document_embeddings = model.encode(documents)\n",
    "\n",
    "similarity = model.similarity(query_embeddings, document_embeddings)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a21727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6607, 0.7754, 0.5711, 0.5999]])\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    'ì„ ë¶ˆì¹´ë“œë¥¼ ë¯¸ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì”ì•¡ì´ ì‚¬ë¼ì§ˆ ìˆ˜ë„ ìˆë‚˜?'\n",
    "]\n",
    "\n",
    "documents = [\n",
    "\"\"\"ì œ2ì¡° (ì •ì˜) ì´ ì•½ê´€ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ì •ì˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. \"íšŒì›\"ì´ë€ ì´ ì•½ê´€ì„ ìŠ¹ì¸í•˜ê³  ì¹´ë“œì‚¬ì— ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ ë°œê¸‰ì„ ì‹ ì²­í•˜ì—¬, ì¹´ë“œì‚¬ë¡œë¶€í„° ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œë¥¼ ë°œê¸‰ë°›ì•„ ì‚¬ìš©í•˜ëŠ” ìë¥¼ ë§í•©ë‹ˆë‹¤. \"ì†Œì§€ì\"ë€ ì´ ì•½ê´€ì„ ìŠ¹ì¸í•˜ê³  ì¹´ë“œì‚¬ì— ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œì˜ êµ¬ë§¤ë¥¼ ì‹ ì²­í•œ í›„ ì¹´ë“œì‚¬ë¡œë¶€í„° ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œë¥¼ êµ¬ë§¤í•˜ì—¬ ì†Œì§€í•˜ê±°ë‚˜, êµ¬ë§¤í•œ ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ìë¥¼ ë§í•©ë‹ˆë‹¤. \"ì„ ë¶ˆì¹´ë“œ\"ë€ ì¹´ë“œì‚¬ê°€ ëŒ€ê¸ˆì„ ë¯¸ë¦¬ ë°›ê³  ì´ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ì„ ê¸°ë¡(ì „ìì  ë˜ëŠ” ìê¸°ì  ë°©ë²•ì— ë”°ë¥¸ ê¸°ë¡ì„ ë§í•œë‹¤)í•˜ì—¬ ë°œí–‰í•œ ì¦í‘œ ë˜ëŠ” ê·¸ ì¦í‘œì— ê´€í•œ ì •ë³´ë¡œì„œ íšŒì› ë“±ì´ ê°€ë§¹ì ì— ì œì‹œí•˜ì—¬ ê·¸ ì¹´ë“œì— ê¸°ë¡ëœ ê¸ˆì•¡ì˜ ë²”ìœ„ì—ì„œ ê²°ì œí•  ìˆ˜ ìˆê²Œ í•œ ì¦í‘œ ë˜ëŠ” ê·¸ ì¦í‘œì— ê´€í•œ ì •ë³´ë¥¼ ë§í•©ë‹ˆë‹¤. \"ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ\"ë€ íšŒì›ì´ ì¹´ë“œì‚¬ì— ì‹ ì²­í•˜ì—¬ ë°œê¸‰ë°›ì€ ì„ ë¶ˆì¹´ë“œë¡œì„œ ì¹´ë“œì‹¤ë¬¼ì— íšŒì›ì˜ ì„±ëª…ì´ ì¸ì‡„ë˜ì–´ ìˆê±°ë‚˜ ì¹´ë“œì‚¬ ì „ì‚°ì— ê¸°ëª…ì‹ íšŒì›ìœ¼ë¡œì„œì˜ ì •ë³´ê°€ ì¡´ì¬í•˜ëŠ” ì¹´ë“œë¥¼ ì˜ë¯¸í•˜ê³  ë°œê¸‰ ì´í›„ ì–‘ë„ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. \"ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ\"ë€ ê³ ê°ì´ ì¹´ë“œì‚¬ì— ì‹ ì²­í•˜ì—¬ êµ¬ë§¤í•œ ì„ ë¶ˆì¹´ë“œë¡œì„œ ì¹´ë“œ ì‹¤ë¬¼ì— ì„±ëª…ì´ ë¯¸ì¸ì‡„ë˜ì–´ ìˆìœ¼ë©° ì¹´ë“œì‚¬ ì „ì‚°ì— ê¸°ëª…ì‹ íšŒì›ìœ¼ë¡œì„œì˜ ì •ë³´ê°€ ì¡´ì¬í•˜ì§€ ì•Šê³  ì–‘ë„ê°€ ê°€ëŠ¥í•œ ì„ ë¶ˆì¹´ë“œë¥¼ ë§í•©ë‹ˆë‹¤. ë‹¨, ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œì˜ ì†Œì§€ìê°€ ì¸í„°ë„· ì‚¬ìš©ë“±ë¡, ì†Œë“ê³µì œ ë“±ë¡, ì¹´ë“œì´ìš©ë‚´ì—­ ì•ˆë‚´ íœ´ëŒ€í° ë¬¸ìë©”ì‹œì§€ ì„œë¹„ìŠ¤ë¥¼ ì‹ ì²­í•œ ê²½ìš° ì¹´ë“œì‚¬ ì „ì‚°ì— í•´ë‹¹ ì†Œì§€ìì˜ ì •ë³´ê°€ ì¡´ì¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \"ì¶©ì „\"ì´ë€ ì„ ë¶ˆì¹´ë“œë¡œ êµ¬ë§¤í–‰ìœ„ë¥¼ í•˜ê¸° ìœ„í•´ ê¶Œë©´ê¸ˆì•¡ ë˜ëŠ” ê´€ê³„ë²•ë ¹ ë° ì´ ì•½ê´€ì´ ì •í•œ ë²”ìœ„ ë‚´ì—ì„œ íšŒì› ë“±ì´ ì›í•˜ëŠ” ë§Œí¼ì˜ ê¸ˆì•¡ì„ ì¹´ë“œì‚¬ ì˜ì—…ì , í™ˆí˜ì´ì§€ ë“±ì„ í†µí•´ ì¹´ë“œì‚¬ê°€ ì •í•œ ë°©ë²•ì— ì˜í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥í•œ ìƒíƒœë¡œ ë°”ê¾¸ëŠ” ê²ƒì„ ë§í•©ë‹ˆë‹¤. \"ì„ ë¶ˆì¹´ë“œì˜ ìœ íš¨ê¸°í•œ\"ì´ë€ ì¹´ë“œì‚¬ë¡œë¶€í„° ì„ ë¶ˆì¹´ë“œë¥¼ ë°œê¸‰ë°›ì•„ ê°€ë§¹ì ì— ì œì‹œí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¸°ê°„ì„ ë§í•©ë‹ˆë‹¤. \"ì†Œë©¸ì‹œíš¨ê¸°ê°„\"ì´ë€ íšŒì› ë“±ì´ ì¹´ë“œì‚¬ì— ëŒ€í•˜ì—¬ ì„ ë¶ˆì¹´ë“œìƒ ì¶©ì „ëœ ê¸ˆì•¡ì˜ ì‚¬ìš© ë° ë°˜í™˜ì„ ìš”êµ¬í•  ìˆ˜ ìˆëŠ” ê¸°ê°„ì„ ë§í•©ë‹ˆë‹¤. ì œ 2 ì¥ ì„ ë¶ˆì¹´ë“œì˜ ë°œê¸‰ ë° ì´ìš© ë“± ì œ3ì¡° (ì„ ë¶ˆì¹´ë“œì˜ ë°œê¸‰ ë° êµ¬ë§¤) íšŒì› ë“±ì´ ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œì˜ ë°œê¸‰ ë˜ëŠ” ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œì˜ êµ¬ë§¤ë¥¼ í¬ë§í•  ê²½ìš° ì§€ì •íŒë§¤ì²˜ ë“±ì„ í†µí•´ ì¹´ë“œì‚¬ê°€ ì •í•œ ë°©ë²•ìœ¼ë¡œ ì‹ ì²­í•  ìˆ˜ ìˆìœ¼ë©°, ì„ ë¶ˆì¹´ë“œì˜ ë°œê¸‰ë§¤ìˆ˜ ë° ë°œê¸‰ìê²©ì€ ì¹´ë“œì‚¬ê°€ ë³„ë„ë¡œ ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íšŒì› ë“±ì´ ì„ ë¶ˆì¹´ë“œì˜ ë°œê¸‰ ë° êµ¬ë§¤ë¥¼ ì‹ ì²­í•  ê²½ìš° ì¹´ë“œì‚¬ëŠ” ë³„ë„ì˜ ì œì‘ë¹„ìš©ì„, ë°°ì†¡ì´ í•„ìš”í•œ ê²½ìš° ë³„ë„ì˜ ë°°ì†¡ë£Œë¥¼ ì²­êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„ ë¶ˆì¹´ë“œì— ëŒ€í•œ ë³„ë„ì˜ ì—°íšŒë¹„ëŠ” ì—†ìœ¼ë©°, ì„ ë¶ˆì¹´ë“œë¥¼ ë°œê¸‰(ì¬ë°œê¸‰)ë°›ëŠ” ê²½ìš° ì¹´ë“œì‚¬ëŠ” ì„ ë¶ˆì¹´ë“œì˜ ë°œê¸‰ì— ìš°ì„ í•˜ì—¬ ë°œê¸‰ìˆ˜ìˆ˜ë£Œ ë“±ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¹´ë“œì‚¬ëŠ” ì„ ë¶ˆì¹´ë“œë¥¼ ë°œê¸‰í•˜ê±°ë‚˜ íŒë§¤í•˜ëŠ” ê²½ìš° íšŒì› ë“±ì—ê²Œ ë¶€ê°€ì„œë¹„ìŠ¤, ì´ìš©í•œë„, ë¶€ëŒ€ë¹„ìš©, ì‚¬ìš©ë¶ˆê°€Â·ì œí•œ ê°€ë§¹ì ëª… ë° ê±°ë˜ìœ í˜•ì— ê´€í•œ ëª©ë¡, ì¸í„°ë„· ì‚¬ìš©ë“±ë¡Â·ì†Œë“ê³µì œì˜ ë°©ë²• ë“± ì¤‘ìš”ì‚¬í•­ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ì œ4ì¡°(ì„ ë¶ˆì¹´ë“œì˜ ìœ íš¨ê¸°í•œ ë° ì¬ë°œê¸‰) ì¹´ë“œì‚¬ëŠ” ì„ ë¶ˆì¹´ë“œ ë°œê¸‰ ì‹œ ì „ì‚° ê´€ë¦¬ ë° ì¸í„°ë„· ê±°ë˜ ë“±ì„ ìœ„í•˜ì—¬ ì„ ë¶ˆì¹´ë“œ í‘œë©´ì— ìœ íš¨ê¸°í•œì„ ê¸°ì¬í•˜ì—¬ êµë¶€í•©ë‹ˆë‹¤.\"\"\",\n",
    "\"\"\"ì œ5ì¡°(ì„ ë¶ˆì¹´ë“œì™€ ì†Œë©¸ì‹œíš¨) ê¸°ì‚¬ìš© ì„ ë¶ˆì¹´ë“œì˜ ì”ì•¡ì€ ìµœì¢…ì‚¬ìš©ì›”ë¡œë¶€í„°, ë¯¸ì‚¬ìš© ì„ ë¶ˆì¹´ë“œì˜ ì”ì•¡ì€ íŒë§¤ì›”(ë˜ëŠ” ì¶©ì „ì›”)ë¡œë¶€í„° 5ë…„ì´ ê²½ê³¼í•˜ë©´ ì†Œë©¸ë©ë‹ˆë‹¤. ë‹¤ë§Œ, ì†Œë©¸ì‹œíš¨ê¸°ê°„ì€ 5ë…„ë³´ë‹¤ ê¸¸ê²Œ ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¹´ë“œì‚¬ëŠ” ì†Œë©¸ì‹œíš¨ê°€ ì™„ì„±ëœ ì„ ë¶ˆì¹´ë“œì˜ ë¯¸ì‚¬ìš© ì”ì•¡ì„ ì—¬ì‹ ì „ë¬¸ê¸ˆìœµì—…í˜‘íšŒê°€ ì„¤ë¦½í•œ ê¸°ë¶€ê¸ˆê´€ë¦¬ì¬ë‹¨ì— ê¸°ë¶€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ, ì¹´ë“œì‚¬ëŠ” 5ë§Œì› ì´ìƒì˜ ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ ë¯¸ì‚¬ìš© ì”ì•¡ì„ ê¸°ë¶€í•˜ëŠ” ê²½ìš° ê¸°ë¶€í•˜ê¸° 1ê°œì›” ì „ê¹Œì§€ ë‹¤ìŒ ê° í˜¸ì˜ ì‚¬í•­ì„ í¬í•¨í•˜ì—¬ ì„œë©´(æ›¸é¢), ìš°í¸, ì „ììš°í¸(E-MAIL), ì „í™”, íŒ©ìŠ¤, íœ´ëŒ€ì „í™” ë¬¸ìë©”ì‹œì§€, ì „ìë¬¸ì„œ ì¤‘ í•œ ê°€ì§€ ì´ìƒì˜ ë°©ë²•ìœ¼ë¡œ íšŒì›ì—ê²Œ í†µì§€í•©ë‹ˆë‹¤. ê¸°ë¶€ê¸ˆ ì•¡ìˆ˜ ê¸°ë¶€ì˜ˆì •ì¼ ê¸°ë¶€ì²˜ ê¸°ë¶€ì— ê´€í•œ í†µì§€ì— ëŒ€í•˜ì—¬ íšŒì›ì€ í†µì§€ë°›ì€ ë‚ ë¡œë¶€í„° 30ì¼ ì´ë‚´ì— ì´ì˜ë¥¼ ì œê¸°í•  ìˆ˜ ìˆìœ¼ë©°, í•´ë‹¹ê¸°ê°„ ë‚´ ë³„ë„ì˜ ì´ì˜ë¥¼ ì œê¸°í•˜ì§€ ì•„ë‹ˆí•˜ëŠ” ê²½ìš° ê¸°ë¶€ì— ë™ì˜í•œ ê²ƒìœ¼ë¡œ ë³¸ë‹¤ëŠ” ì‚¬ì‹¤ ì œ2í•­ì— ë”°ë¼ ê¸°ë¶€ì˜ˆì • í†µì§€ë¥¼ í•œ ì¹´ë“œì‚¬ëŠ” ì„œëª…(ì „ìì„œëª… í¬í•¨), ê¸°ëª…ë‚ ì¸, ë…¹ì·¨, ì „í™”ìë™ì‘ë‹µì‹œìŠ¤í…œ, íœ´ëŒ€í° ë¬¸ìë©”ì‹œì§€ ì„œë¹„ìŠ¤ ì¤‘ í•˜ë‚˜ì˜ ë°©ë²•ìœ¼ë¡œ íšŒì›ì—ê²Œ ë™ì˜ë¥¼ ì–»ì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë§Œ, í†µì§€ë¥¼ ë°›ì€ íšŒì›ì´ 30ì¼ ì´ë‚´ì— ì´ì˜ë¥¼ ì œê¸°í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ” ê¸°ë¶€ì— ë™ì˜í•œ ê²ƒìœ¼ë¡œ ë´…ë‹ˆë‹¤. ì œ6ì¡°(ì„ ë¶ˆì¹´ë“œì˜ ì´ìš©) ì„ ë¶ˆì¹´ë“œëŠ” ì¼ì‹œë¶ˆ êµ¬ë§¤ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë©°, íšŒì› ë“±ì´ ì„ ë¶ˆì¹´ë“œë¡œ ìƒí’ˆì„ êµ¬ë§¤í•˜ê±°ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ì œê³µë°›ê³ ì í•  ë•Œì—ëŠ” êµ­ë‚´ì˜ ê²½ìš°ì—ëŠ” ì¹´ë“œì‚¬ ë˜ëŠ” ì¹´ë“œì‚¬ì™€ ì œíœ´í•œ ê¸°ê´€ì˜ ê°€ë§¹ì (ì´í•˜ \"êµ­ë‚´ê°€ë§¹ì \"ì´ë¼ í•¨), êµ­ì™¸ì˜ ê²½ìš°ì—ëŠ” ì¹´ë“œì‚¬ì™€ ì œíœ´í•˜ê³  ìˆëŠ” ì™¸êµ­ê¸°ê´€ì˜ ê°€ë§¹ì (ì´í•˜ \"í•´ì™¸ê°€ë§¹ì \"ì´ë¼ í•¨)ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„ ë¶ˆì¹´ë“œ íšŒì› ë“±ì€ ì¶©ì „ëœ ì„ ë¶ˆì¹´ë“œ ì”ì•¡ ë²”ìœ„ ë‚´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íšŒì› ë“±ì´ ì„ ë¶ˆì¹´ë“œ ì‚¬ìš© ì‹œ ì¹´ë“œì‚¬ëŠ” í•´ë‹¹ ì„ ë¶ˆì¹´ë“œì˜ ì¶©ì „ê¸ˆì•¡ì—ì„œ ê²°ì œê¸ˆì•¡ë§Œí¼ì„ ì¦‰ì‹œ ì°¨ê°í•©ë‹ˆë‹¤. ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ íšŒì›ì€ ì„ ë¶ˆì¹´ë“œë¥¼ ì œì‹œí•˜ê³  ë§¤ì¶œì „í‘œì— ì„ ë¶ˆì¹´ë“œ ìƒì˜ ì„œëª…ê³¼ ë™ì¼í•œ ì„œëª…ì„, ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ ì†Œì§€ìëŠ” ì„ ë¶ˆì¹´ë“œë¥¼ ì œì‹œí•˜ê³  ë§¤ì¶œì „í‘œì— ë³¸ì¸ì˜ ì„œëª…ì„ í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤. ì „ììƒê±°ë˜, í†µì‹ íŒë§¤ ë“±ì— ìˆì–´ì„œ ê°€ë§¹ì ì´ ë³¸ì¸í™•ì¸ì„ í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ë°©ë²•ì´ ìˆëŠ” ê²½ìš°ì´ê±°ë‚˜ ì„ ë¶ˆì¹´ë“œì˜ ì œì‹œì™€ ì„œëª… ìƒëµìœ¼ë¡œ ì…ì„ ìˆ˜ ìˆëŠ” ì†Œì§€ìì˜ í”¼í•´ë¥¼ ì¹´ë“œì‚¬ ë˜ëŠ” ê°€ë§¹ì ì´ ë¶€ë‹´í•˜ëŠ” ê²½ìš°ì—ëŠ” ì œ4í•­ì— ë”°ë¥¸ ì„œëª…ì„ ìƒëµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì œ7ì¡°(ì„ ë¶ˆì¹´ë“œì˜ ì´ìš© ì œí•œ) ì„ ë¶ˆì¹´ë“œëŠ” ì¹´ë“œì‚¬ì˜ ê°€ë§¹ì ì—ì„œ ì‹ ìš©ì¹´ë“œì™€ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë‚˜, ê°€ë§¹ì ì˜ ê²°ì œê±°ë¶€Â·ì œí•œ ë“±ìœ¼ë¡œ ì¼ë¶€ ì‚¬ìš©ì´ ì œí•œë  ìˆ˜ ìˆìœ¼ë©°, ì¹´ë“œì‚¬ëŠ” ê°€ë§¹ì ì´ ì„ ë¶ˆì¹´ë“œ ê²°ì œë¥¼ ê±°ë¶€í•˜ê±°ë‚˜ ì œí•œí•˜ëŠ” ê²ƒì„ ì•Œê²Œ ëœ ê²½ìš°, ì§€ì²´ ì—†ì´ íšŒì‚¬ í™ˆí˜ì´ì§€ ë“±ì„ í†µí•´ í•´ë‹¹ ê°€ë§¹ì  ë° ëŒ€ìƒ ê±°ë˜ ìœ í˜•ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ì¹´ë“œì‚¬ëŠ” ë‹¤ìŒ ê° í˜¸ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ê²½ìš°ì—ëŠ” íšŒì› ë“±ì˜ ì„ ë¶ˆì¹´ë“œ ì‚¬ìš©ì„ ì œí•œí•  ìˆ˜ ìˆìœ¼ë©°, ì¹´ë“œì‚¬ í™ˆí˜ì´ì§€ ë“±ì„ í†µí•´ ì‚¬ìš©ì´ ì œí•œëœ ê°€ë§¹ì ì„ ê³ ì§€í•©ë‹ˆë‹¤. ì„ ë¶ˆì¹´ë“œ íŠ¹ì„±ìƒ ì·¨ê¸‰ì— ì–´ë ¤ì›€ì´ ìˆëŠ” ë¬´ìŠ¹ì¸ ê±°ë˜(í•­ê³µê¸° ë‚´ êµ¬ë§¤ ë“±)ì˜ ê²½ìš° ì„ ë¶ˆì¹´ë“œ ìƒí’ˆ ì¶œì‹œ ì‹œ, íŠ¹ì • ê¸°ê´€ê³¼ ì œíœ´ë¥¼ í†µí•´ ì‚¬ìš©ì²˜ë¥¼ ì œí•œí•˜ëŠ” ê²½ìš°\"\"\",\n",
    "\"\"\"ì œ17ì¡°(ì´ìš©ì•½ê´€ì˜ ë³€ê²½) ì´ ì•½ê´€ì„ ë³€ê²½í•  ê²½ìš° ì¹´ë“œì‚¬ëŠ” ê·¸ ë‚´ìš©ì„ ë³€ê²½ ì•½ê´€ ì‹œí–‰ì¼ë¡œë¶€í„° 1ê°œì›” ì´ì „ê¹Œì§€ ì¹´ë“œì‚¬ í™ˆí˜ì´ì§€ì— ê²Œì‹œ(ê¸°ì¡´ ê°€ì…ìì— ëŒ€í•œ ë³€ê²½ì•½ê´€ì˜ ì ìš©ì—¬ë¶€, ì‹ .êµ¬ëŒ€ë¹„í‘œ í¬í•¨)í•˜ê³  íšŒì› ë“±(ë‹¨, ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ ì†Œì§€ìì˜ ê²½ìš° ì¸í„°ë„· ì‚¬ìš©ë“±ë¡, ì†Œë“ê³µì œ ë“±ë¡, ì¹´ë“œì´ìš©ë‚´ì—­ ì•ˆë‚´ íœ´ëŒ€í° ë¬¸ìë©”ì‹œì§€ ì„œë¹„ìŠ¤ ì‹ ì²­ìœ¼ë¡œ ì¹´ë“œì‚¬ì— í•´ë‹¹ ì†Œì§€ìì˜ ì •ë³´ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì— í•œí•¨)ì—ê²Œ ì„œë©´(æ›¸é¢), ìš°í¸, ì „ììš°í¸(E-MAIL), ì „í™”, íŒ©ìŠ¤, íœ´ëŒ€ì „í™” ë¬¸ìë©”ì‹œì§€, ì „ìë¬¸ì„œ ì¤‘ í•œ ê°€ì§€ ì´ìƒì˜ ë°©ë²•ìœ¼ë¡œ ê°œë³„í†µì§€(ì‹ Â·êµ¬ëŒ€ë¹„í‘œ í¬í•¨)í•©ë‹ˆë‹¤. ë‹¤ë§Œ, ë‹¤ìŒ ê° í˜¸ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ê²½ìš°ì—ëŠ” ë³€ê²½ëœ ì•½ê´€ì„ ì¦‰ì‹œ ê²Œì‹œ ë° ê°œë³„ í†µì§€í•˜ì—¬ ë“œë¦½ë‹ˆë‹¤. ë²•ë ¹ ê°œì •, ì œë„ ê°œì„ , ì•½ê´€ ë³€ê²½ê¶Œê³ (ëª…ë ¹) ë“±ìœ¼ë¡œ ê¸´ê¸‰íˆ ì•½ê´€ì„ ë³€ê²½í•œ ê²½ìš° ì•½ê´€ ê°œì •ì´ íšŒì›ì—ê²Œ ìœ ë¦¬í•œ ê²½ìš° ë³€ê²½ ì „ ë‚´ìš©ì´ ê¸°ì¡´ íšŒì›ì—ê²Œ ê·¸ëŒ€ë¡œ ì ìš©ë˜ëŠ” ê²½ìš° ê¸°ì¡´ ì•½ê´€ì˜ ë‚´ìš©ì´ ì‹¤ì§ˆì ìœ¼ë¡œ ë³€ê²½ë˜ì§€ ì•ŠëŠ” ë‹¨ìˆœí•œ ë¬¸êµ¬ ë³€ê²½ ì „í•­ì˜ ê²½ìš° íšŒì› ë“±ì´ ë³€ê²½ì— ë™ì˜í•˜ì§€ ì•ŠëŠ” ê²½ìš° í†µì§€ì¼ë¡œë¶€í„° 1ê°œì›” ì´ë‚´ì— ê³„ì•½ì„ í•´ì§€í•  ìˆ˜ ìˆìœ¼ë©°, ê³„ì•½í•´ì§€ì˜ ì˜ì‚¬í‘œì‹œë¥¼ ì•ŠëŠ” ê²½ìš°ì—ëŠ” ë³€ê²½ì— ë™ì˜í•œ ê²ƒìœ¼ë¡œ ë³¸ë‹¤ëŠ” ë‚´ìš©ì„ ëª…ì‹œí•˜ì—¬ ê²Œì‹œ ë˜ëŠ” í†µì§€í•©ë‹ˆë‹¤. íšŒì› ë“±ì´ ë³€ê²½ì˜ˆì •ì¼ê¹Œì§€ ì´ì˜ë¥¼ ì œê¸°í•˜ì§€ ì•Šì•˜ì„ ë•Œì—ëŠ” ë³€ê²½ëœ ì•½ê´€ì„ ìŠ¹ì¸í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤. ì œ18ì¡°(ì•½ê´€ì—ì„œ ì •í•˜ì§€ ì•„ë‹ˆí•œ ì‚¬í•­) ì‹ ìš©ì •ë³´ì˜ ì œê³µÂ·ì´ìš©, ì•½ê´€ ìœ„ë°˜ ì‹œì˜ ì±…ì„, ê´€í• ë²•ì› ë“± ì´ ì•½ê´€ì—ì„œ ì •í•˜ì§€ ì•„ë‹ˆí•œ ì‚¬í•­ ë° ê·¸ í•´ì„ì— ê´€í•˜ì—¬ëŠ” ì‹ ìš©ì¹´ë“œ ê°œì¸íšŒì› í‘œì¤€ì•½ê´€, ê´€ê³„ë²•ë ¹ ë˜ëŠ” ìƒê´€ë¡€ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ì œ 3 ì¥ ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ ì œ19ì¡°(ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œì˜ ê´€ë¦¬) íšŒì›ì€ ë°œê¸‰ë°›ì€ ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œë¥¼ ìˆ˜ë ¹í•œ ì¦‰ì‹œ ì¹´ë“œ ì„œëª…ë€ì— ë³¸ì¸ì´ ì§ì ‘ ì„œëª…í•˜ì—¬ì•¼ í•˜ë©° íšŒì› ë³¸ì¸ ì´ì™¸ì˜ ì œ3ìë¡œ í•˜ì—¬ê¸ˆ ì„ ë¶ˆì¹´ë“œë¥¼ ë³´ê´€ ë˜ëŠ” ì†Œì§€í•˜ê²Œ í•˜ê±°ë‚˜ ì´ìš©í•˜ê²Œ í•˜ì—¬ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. íšŒì›ì€ ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œë¥¼ ì œ3ìì—ê²Œ ëŒ€ì—¬í•˜ê±°ë‚˜ ì–‘ë„ ë˜ëŠ” ë‹´ë³´ì˜ ëª©ì ìœ¼ë¡œ ì´ìš©í•  ìˆ˜ ì—†ìœ¼ë©°, ì„ ëŸ‰í•œ ê´€ë¦¬ìë¡œì„œì˜ ì£¼ì˜ë¥¼ ë‹¤í•˜ì—¬ ì„ ë¶ˆì¹´ë“œë¥¼ ì´ìš©Â·ê´€ë¦¬í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤. ì œ 4 ì¥ ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ ì œ20ì¡°(ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œì˜ ê´€ë¦¬) ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œì˜ ë°œí–‰ê¶Œë©´ê¸ˆì•¡ ë˜ëŠ” ì¶©ì „ëœ ê¸ˆì•¡ì„ ëª¨ë‘ ì´ìš©í•œ ì´í›„ ë§¤ì¶œì·¨ì†Œë¥¼ í•  ê²½ìš°ì—ëŠ” ì¹´ë“œì‹¤ë¬¼ì´ í•„ìš”í•˜ë¯€ë¡œ ì†Œì§€ìëŠ” ì¹´ë“œì‹¤ë¬¼ì„ ì¼ì •ê¸°ê°„ ë³´ê´€í•œ í›„ íê¸°í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë§Œ, ì¹´ë“œì‹¤ë¬¼ ì—†ì´ ì˜ìˆ˜ì¦ ë“±ì„ í†µí•´ ë§¤ì¶œì·¨ì†Œë¥¼ ìš”ì²­í•˜ëŠ” ê²½ìš°, ì·¨ì†Œ ëŒ€ìƒ ë§¤ì¶œ ë°œìƒ ì‹œ ì •ë‹¹í•œ ì„ ë¶ˆì¹´ë“œ ì†Œì§€ìì„ì´ í™•ì¸ë˜ë©´ ë§¤ì¶œì·¨ì†Œê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì œ21ì¡°(ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œì˜ ì¸í„°ë„· ì‚¬ìš©ë“±ë¡) ì†Œì§€ìëŠ” ì„ ë¶ˆì¹´ë“œë¥¼ ì¹´ë“œì‚¬ì˜ ê°€ë§¹ì ì—ì„œ ë³„ë„ì˜ ë¹„ë°€ë²ˆí˜¸ ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë‚˜, ì¸í„°ë„·ì„ ì´ìš©í•œ ì „ììƒê±°ë˜ì‹œì—ëŠ” ì‚¬ì „ì— ì¹´ë“œì‚¬ í™ˆí˜ì´ì§€ ë“±ì„ í†µí•´ ì¸í„°ë„· ì‚¬ìš©ë“±ë¡ í›„ ì´ìš©í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\"\"\",\n",
    "\"\"\"íšŒì› ë“±ì´ ì œ3í˜¸ì— ë”°ë¥¸ ì¶”ê°€ì ì¸ ë³´ì•ˆì¡°ì¹˜ì— ì‚¬ìš©ë˜ëŠ” ë§¤ì²´Â·ìˆ˜ë‹¨ ë˜ëŠ” ì •ë³´ì— ëŒ€í•˜ì—¬ ë‹¤ìŒ ê° ëª©ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” í–‰ìœ„ë¥¼ í•˜ì—¬ ì „ìê¸ˆìœµê±°ë˜ë¥¼ ìœ„í•œ ì „ìì  ì¥ì¹˜ ë˜ëŠ” ì •ë³´í†µì‹ ë§ì— ì¹¨ì…í•œ ì œ3ìê°€ ê±°ì§“ì´ë‚˜ ê·¸ ë°–ì˜ ë¶€ì •í•œ ë°©ë²•ìœ¼ë¡œ íšë“í•œ ì ‘ê·¼ë§¤ì²´ë¥¼ ì´ìš©í•˜ì—¬ ë°œìƒí•œ ì‚¬ê³ ì˜ ê²½ìš° ê°€. ëˆ„ì„¤Â·ë…¸ì¶œ ë˜ëŠ” ë°©ì¹˜í•œ í–‰ìœ„ ë‚˜. ì œ3ìì—ê²Œ ëŒ€ì—¬í•˜ê±°ë‚˜ ê·¸ ì‚¬ìš©ì„ ìœ„ì„í•œ í–‰ìœ„ ë˜ëŠ” ì–‘ë„ë‚˜ ë‹´ë³´ì˜ ëª©ì ìœ¼ë¡œ ì œê³µí•œ í–‰ìœ„ íšŒì› ë“±ì€ ì œ2í•­ ê° í˜¸ì™€ ê´€ë ¨í•˜ì—¬ ì‚¬ê³ ì¡°ì‚¬ê°€ í•„ìš”í•œ ê²½ìš° ì¹´ë“œì‚¬ì˜ ìš”êµ¬ì— í˜‘ì¡°í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤. ì œ15ì¡°(ë³€ê²½ì‚¬í•­ì˜ í†µì§€) ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ íšŒì›ì€ ì£¼ì†Œ, ì „í™”ë²ˆí˜¸, ì „ììš°í¸(E-MAIL) ë“±ì˜ ë³€ê²½ì‚¬í•­ì´ ìˆì„ ë•Œ ì¹´ë“œì‚¬ì— ì¦‰ì‹œ í†µì§€í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤. ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ ì†Œì§€ì ì¤‘ ì¸í„°ë„· ì‚¬ìš©ë“±ë¡, ì†Œë“ê³µì œë“±ë¡, ì¹´ë“œì´ìš©ë‚´ì—­ ì•ˆë‚´ íœ´ëŒ€í° ë¬¸ìë©”ì‹œì§€ ì„œë¹„ìŠ¤ë¥¼ ì‹ ì²­í•˜ì—¬ ì†Œì§€ìì˜ ì •ë³´ë¥¼ ë“±ë¡í•œ ê²½ìš°, ë“±ë¡ì •ë³´ì˜ ë³€ê²½ì‚¬í•­ì´ ìˆì„ ë•Œ ì¹´ë“œì‚¬ì— ì¦‰ì‹œ í†µì§€í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤. íšŒì› ë“±ì´ ì œ1í•­ ë° ì œ2í•­ì˜ í†µì§€ë¥¼ íƒœë§Œíˆ í•˜ì—¬ ì¹´ë“œì‚¬ê°€ ê³¼ì‹¤ ì—†ì´ íšŒì› ë“±ì˜ ë³€ê²½ëœ ì£¼ì†Œ ë“±ì„ ì•Œì§€ ëª»í•˜ëŠ” ê²½ìš°ì— í•œí•˜ì—¬, ì¹´ë“œì‚¬ë¡œë¶€í„° í†µì§€ ë˜ëŠ” ì†¡ë¶€ì„œë¥˜ ë“±ì´ ëŠ¦ê²Œ ë„ì°©í•˜ê±°ë‚˜ ë„ì°©í•˜ì§€ ì•ŠìŒìœ¼ë¡œ ì¸í•˜ì—¬ ë°œìƒí•œ ì†í•´ëŠ” íšŒì› ë“±ì´ ë¶€ë‹´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤. ì´ ê²½ìš° í†µìƒ ë„ì°©í•˜ì—¬ì•¼ í•  ë•Œì— íšŒì› ë“±ì—ê²Œ ë„ì°©í•œ ê²ƒìœ¼ë¡œ í•˜ì—¬ ê·¸ ë„ì°©ìœ¼ë¡œ ì¸í•œ ë²•ë¥ íš¨ê³¼ê°€ ë°œìƒí•©ë‹ˆë‹¤. ì œ16ì¡°(ì´ìš©ì•½ê´€ì˜ íš¨ë ¥) ì´ ì•½ê´€ì˜ ë‚´ìš©ì€ ì¹´ë“œì‚¬ê°€ ì œê³µí•˜ëŠ” ì¸í„°ë„· í™ˆí˜ì´ì§€ ë“±ì— ê²Œì‹œí•˜ê±°ë‚˜ ì„ ë¶ˆì¹´ë“œì˜ êµ¬ë§¤Â·ë°œê¸‰ ì‹œ ì•½ê´€ì„ êµë¶€í•˜ëŠ” ë“±ì˜ ë°©ë²•ìœ¼ë¡œ íšŒì› ë“±ì—ê²Œ ê³µì§€í•¨ìœ¼ë¡œì¨ íš¨ë ¥ì„ ë°œìƒí•©ë‹ˆë‹¤. ë‹¨, ë¬´ê¸°ëª…ì‹ ì„ ë¶ˆì¹´ë“œ ì–‘ë„ì˜ ê²½ìš° ì–‘ë„í•œ ë•Œì— ì´ ì•½ê´€ì˜ íš¨ë ¥ì´ ë°œìƒ ë˜ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.\"\"\"\n",
    "]\n",
    "\n",
    "query_embeddings = model.encode(queries, prompt_name=\"query\")\n",
    "document_embeddings = model.encode(documents)\n",
    "\n",
    "similarity = model.similarity(query_embeddings, document_embeddings)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7eed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"},]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": \"Write a poem on Hugging Face, the company\"},]\n",
    "        },\n",
    "    ],\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f577b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "model_a = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc3100a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[-14.2266,  -1.1276,   4.6604,  ..., -14.7097, -14.7547, -14.6708],\n",
       "         [-11.2772,  -0.6546,  -5.0065,  ..., -11.6818, -11.6677, -11.6955],\n",
       "         [-22.6223,   6.3905,   4.9708,  ..., -23.9000, -23.9398, -24.0407],\n",
       "         ...,\n",
       "         [ -8.5231,   6.3015,  -3.5652,  ..., -10.6850, -10.6294, -10.6779],\n",
       "         [-22.1560,   3.1504,  12.3382,  ..., -22.5151, -22.5003, -22.3365],\n",
       "         [-15.3647, -13.0501,  -1.1583,  ..., -16.5285, -16.7630, -16.4063]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=<transformers.cache_utils.HybridCache object at 0x000002848E8B8B10>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e6ac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen: vision_tower.vision_model.embeddings.patch_embedding.weight\n",
      "Frozen: vision_tower.vision_model.embeddings.patch_embedding.bias\n",
      "Frozen: vision_tower.vision_model.embeddings.position_embedding.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.0.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.1.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.2.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.3.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.4.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.5.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.6.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.7.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.8.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.9.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.10.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.11.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.12.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.13.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.14.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.15.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.16.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.17.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.18.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.19.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.20.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.21.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.22.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.23.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.24.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.25.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.bias\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.weight\n",
      "Unfrozen: vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.layer_norm1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.layer_norm1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.mlp.fc1.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.mlp.fc1.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.mlp.fc2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.mlp.fc2.bias\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.layer_norm2.weight\n",
      "Frozen: vision_tower.vision_model.encoder.layers.26.layer_norm2.bias\n",
      "Frozen: vision_tower.vision_model.post_layernorm.weight\n",
      "Frozen: vision_tower.vision_model.post_layernorm.bias\n",
      "Frozen: multi_modal_projector.mm_input_projection_weight\n",
      "Frozen: multi_modal_projector.mm_soft_emb_norm.weight\n",
      "Unfrozen: language_model.model.embed_tokens.weight\n",
      "Frozen: language_model.model.layers.0.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.0.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.0.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.0.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.0.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.0.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.0.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.0.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.0.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.0.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.0.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.0.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.0.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.1.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.1.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.1.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.1.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.1.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.1.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.1.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.1.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.1.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.1.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.1.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.1.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.1.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.2.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.2.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.2.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.2.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.2.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.2.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.2.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.2.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.2.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.2.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.2.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.2.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.2.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.3.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.3.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.3.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.3.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.3.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.3.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.3.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.3.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.3.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.3.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.3.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.3.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.3.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.4.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.4.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.4.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.4.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.4.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.4.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.4.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.4.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.4.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.4.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.4.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.4.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.4.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.5.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.5.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.5.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.5.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.5.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.5.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.5.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.5.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.5.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.5.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.5.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.5.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.5.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.6.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.6.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.6.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.6.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.6.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.6.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.6.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.6.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.6.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.6.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.6.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.6.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.6.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.7.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.7.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.7.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.7.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.7.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.7.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.7.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.7.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.7.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.7.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.7.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.7.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.7.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.8.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.8.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.8.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.8.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.8.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.8.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.8.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.8.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.8.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.8.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.8.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.8.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.8.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.9.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.9.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.9.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.9.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.9.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.9.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.9.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.9.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.9.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.9.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.9.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.9.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.9.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.10.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.10.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.10.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.10.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.10.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.10.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.10.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.10.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.10.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.10.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.10.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.10.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.10.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.11.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.11.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.11.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.11.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.11.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.11.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.11.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.11.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.11.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.11.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.11.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.11.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.11.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.12.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.12.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.12.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.12.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.12.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.12.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.12.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.12.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.12.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.12.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.12.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.12.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.12.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.13.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.13.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.13.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.13.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.13.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.13.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.13.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.13.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.13.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.13.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.13.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.13.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.13.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.14.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.14.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.14.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.14.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.14.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.14.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.14.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.14.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.14.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.14.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.14.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.14.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.14.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.15.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.15.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.15.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.15.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.15.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.15.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.15.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.15.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.15.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.15.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.15.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.15.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.15.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.16.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.16.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.16.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.16.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.16.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.16.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.16.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.16.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.16.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.16.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.16.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.16.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.16.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.17.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.17.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.17.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.17.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.17.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.17.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.17.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.17.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.17.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.17.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.17.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.17.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.17.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.18.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.18.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.18.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.18.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.18.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.18.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.18.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.18.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.18.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.18.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.18.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.18.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.18.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.19.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.19.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.19.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.19.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.19.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.19.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.19.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.19.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.19.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.19.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.19.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.19.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.19.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.20.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.20.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.20.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.20.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.20.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.20.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.20.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.20.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.20.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.20.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.20.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.20.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.20.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.21.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.21.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.21.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.21.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.21.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.21.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.21.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.21.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.21.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.21.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.21.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.21.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.21.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.22.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.22.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.22.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.22.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.22.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.22.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.22.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.22.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.22.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.22.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.22.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.22.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.22.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.23.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.23.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.23.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.23.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.23.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.23.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.23.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.23.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.23.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.23.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.23.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.23.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.23.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.24.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.24.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.24.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.24.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.24.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.24.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.24.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.24.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.24.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.24.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.24.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.24.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.24.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.25.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.25.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.25.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.25.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.25.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.25.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.25.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.25.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.25.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.25.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.25.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.25.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.25.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.26.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.26.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.26.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.26.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.26.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.26.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.26.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.26.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.26.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.26.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.26.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.26.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.26.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.27.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.27.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.27.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.27.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.27.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.27.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.27.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.27.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.27.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.27.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.27.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.27.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.27.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.28.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.28.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.28.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.28.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.28.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.28.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.28.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.28.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.28.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.28.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.28.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.28.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.28.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.29.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.29.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.29.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.29.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.29.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.29.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.29.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.29.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.29.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.29.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.29.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.29.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.29.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.30.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.30.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.30.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.30.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.30.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.30.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.30.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.30.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.30.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.30.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.30.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.30.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.30.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.31.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.31.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.31.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.31.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.31.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.31.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.31.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.31.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.31.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.31.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.31.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.31.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.31.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.32.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.32.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.32.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.32.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.32.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.32.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.32.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.32.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.32.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.32.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.32.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.32.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.32.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.33.self_attn.q_proj.weight\n",
      "Frozen: language_model.model.layers.33.self_attn.k_proj.weight\n",
      "Unfrozen: language_model.model.layers.33.self_attn.v_proj.weight\n",
      "Frozen: language_model.model.layers.33.self_attn.o_proj.weight\n",
      "Frozen: language_model.model.layers.33.self_attn.q_norm.weight\n",
      "Frozen: language_model.model.layers.33.self_attn.k_norm.weight\n",
      "Frozen: language_model.model.layers.33.mlp.gate_proj.weight\n",
      "Frozen: language_model.model.layers.33.mlp.up_proj.weight\n",
      "Frozen: language_model.model.layers.33.mlp.down_proj.weight\n",
      "Frozen: language_model.model.layers.33.input_layernorm.weight\n",
      "Frozen: language_model.model.layers.33.post_attention_layernorm.weight\n",
      "Frozen: language_model.model.layers.33.pre_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.layers.33.post_feedforward_layernorm.weight\n",
      "Frozen: language_model.model.norm.weight\n"
     ]
    }
   ],
   "source": [
    "def selective_freeze(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        # ì›í•˜ëŠ” ë ˆì´ì–´ë§Œ True, ë‚˜ë¨¸ì§€ëŠ” False\n",
    "        if (\n",
    "            \"v_proj\" in name or \n",
    "            \"embed_tokens\" in name or\n",
    "            \"lm_head\" in name\n",
    "        ):\n",
    "            param.requires_grad = True\n",
    "            print(f\"Unfrozen: {name}\")\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "            print(f\"Frozen: {name}\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "selective_freeze(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839a1247",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Gemma3ForConditionalGeneration' object has no attribute 'print_trainable_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_trainable_parameters\u001b[49m()\n",
      "File \u001b[1;32mc:\\Users\\gkfua\\anaconda3\\envs\\space_0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1930\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Gemma3ForConditionalGeneration' object has no attribute 'print_trainable_parameters'"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ae60ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 796,244,352 | Total params: 4,300,079,472 | Trainable%: 18.52%\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable = 0\n",
    "    total = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        num_params = param.numel()\n",
    "        total += num_params\n",
    "        if param.requires_grad:\n",
    "            trainable += num_params\n",
    "            # print(f\"[Trainable] {name}: {num_params}\")\n",
    "    print(f\"Trainable params: {trainable:,} | Total params: {total:,} | Trainable%: {100 * trainable / total:.2f}%\")\n",
    "\n",
    "# ì˜ˆì‹œ\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e8bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10ffde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "space_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
